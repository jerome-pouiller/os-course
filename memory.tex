%
% This document is available under the Creative Commons Attribution-ShareAlike
% License; additional terms may apply. See
%   * http://creativecommons.org/licenses/by-sa/3.0/
%   * http://creativecommons.org/licenses/by-sa/3.0/legalcode
%
% Copyright 2010 Jérôme Pouiller <jezz@sysmic.org>
%

\part{Gestion de la mémoire}


\begin{frame}
  \partpage
\end{frame}

\begin{frame}
  \tableofcontents
\end{frame}

\subsection{Les différents segments}

\begin{frame}[fragile=singleslide]{Données}
  Les segments \c{.data}, \c{.rodata}, \c{.bss}
  \begin{itemize}
  \item Contiennent les variables globale et statique
  \item Allouée pour \file{ld.so}
  \end{itemize}
\end{frame}

\subsection{La pile}

\begin{frame}[fragile=singleslide]{La pile}
  \begin{columns}
    \begin{column}{6.5cm}
      \begin{itemize}
      \item Permet d'allouer les variable \emph{auto}.
      \item = Variable locales au fonction
      \item La pile système est composée de \emph{frame}
      \item Chaque appel de fonction ajoute une \emph{frame} à la pile
      \item Deux registres sont utilisé pour la pile:
        \begin{itemize}
        \item Stack Pointer (\c{$sp}): Pointe la tête de la pile
        \item  Frame Pointer  (\c{$fp})  ou Base  stack pointer  \c{$bp}):
          Pointe sur (plus ou moins) la base de la frame en cours
        \end{itemize}
      \item On  accède à un variable  locale en lisant  l'adresse \c{$fp + #CONSTANTE}
      \end{itemize}
    \end{column}
    \begin{column}{4cm}
      \pgfimage[width=5cm]{pics/fig3}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{La pile}
  \begin{columns}
    \begin{column}{4cm}
      \begin{itemize}
      \item  Lorsque l'on appel  une fonction,  on sauvegarde  le contexte
        (dont \c{$sp}) à  partir de \c{$sp}, on affecte  \c{$sp} à \c{$fp}
        et on  ajoute la somme de  la taille du contexte  et des variables
        allouées localement à \c{$sp}
      \item Ainsi une allocation locale est très rapide (incrémentation de
        \c{$sp})
      \end{itemize}
    \end{column}
    \begin{column}{6.5cm}
      \begin{overprint}
        \onslide<1>
        
        \onslide<2>
        \pgfimage[width=7cm]{pics/fig3}
        
        \onslide<3>
        \pgfimage[width=7cm]{pics/fig4}
        
        \onslide<4>
        \pgfimage[width=7cm]{pics/fig5}
      \end{overprint}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}[fragile=singleslide]{Allocation dynamique sur la pile}
  \begin{itemize}
  \item   Les   fonctions   avec   un  nombre   variable   d'arguments
    (\emph{variadic functions}, cf  \man{va\_arg(3)}) ont une taille de
    frame variable en fonction du nombre d'arguments.
  \item  Il  est  possible   d'allouer  dynmaiquement  de  la  mémoire
    supplémentaire sur la frame courante: \man{alloca(3)}
  \item C'est ainsi que sont implémentés des choses du genre
    \begin{lstlisting}
void f(int i) {
   char t[i];
}
    \end{lstlisting}
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{\c{omit-framepointer}}
  \begin{itemize}
  \item Il est  possible de travailler avec \c{$sp}  comme base plutôt
     que \c{$fp}.
    \begin{itemize}
    \item Cela permet d'économiser un registre
    \item   Plus   difficile    à   implémenter   car   \c{$sp}   peut
      potentiellement varier
    \item  Les   outils  extérieur  (debuggueur)   ne  peuvent  plus
      retrouver la base de la frame
    \item Option \cmd{-fomit-framepointer}
    \end{itemize}
   \end{itemize}
\end{frame}
% Placer un shema de la pile

\subsection{Le tas}

\begin{frame}[fragile=singleslide]{Le tas}
  \begin{itemize}
  \item Mémoire utilisée par malloc ou new.
  \item  Les  demande  au  Noyau  se font  par  \man{sbrk(2)}  ou  par
    \man{mmap(2)} pour les demandes supérieures ou égale à une page.
  \item malloc ne peut pas utiliser  mmap pour de petits objets car il
    y aurait trop de perte.
  \item  Lors  d'une demande  d'allocation,  \c{malloc} recherche  une
    place dans les pages qu'il a  deja alloué. Si ca n'est pas le cas,
    il appelle \c{sbrk} ou \c{mmap}
  \item malloc ajoute au début  (ou éventuellement à la fin) des blocs
    alloués des information sur la taille du bloc, etc...
  \item Plusieurs algorithme de gestion de \c{malloc}
  \end{itemize}
\end{frame}

\begin{frame}{Liste de blocs}
  Les  liste  de   bloc:  on  utilise  une  liste   chainée  de  blocs
  libre. Lorsqu'on  libére un  bloc, on vérifie  si les  blocs voisins
  sont libres.  On les fusionne si c'était le cas.
  \begin{center}
    \pgfimage[width=10cm]{pics/alloc-freelist}
  \end{center}
  Problème inhérant à cet algorithme: la fragmentation
  \\[2ex]
  Lors  de l'allocation, quatres méthodes.
\end{frame}

\begin{frame}{Liste de blocs}
  \emph{First fit}  On utilise  le premier bloc  assez grand  que l'on
  trouve
  \\
  Exemple (\textbf{A}jout, \textbf{D}elete):
  \begin{center}
    \pgfimage[width=10cm]{pics/alloc-firstfit}
  \end{center}
\end{frame}

\begin{frame}{Liste de blocs}
  \emph{Next  fit} Idem  \emph{First  fit}, mais  on  part du  dernier
  endroit ou a alloué
  \\
  Exemple (\textbf{A}jout, \textbf{D}elete):
  \begin{center}
    \pgfimage[width=10cm]{pics/alloc-nextfit}
  \end{center}
\end{frame}

\begin{frame}{Liste de blocs}
  \emph{Best fit}  On recherche le  bloc disponible de taille  la plus
  proche de  celle nécessaire.  Il s'avère que  cette méthode garantie
  que l'espace inutilisé est petit et cond inutilisable
  \\
  Exemple (\textbf{A}jout, \textbf{D}elete):
  \begin{center}
    \pgfimage[width=10cm]{pics/alloc-bestfit}
  \end{center}
\end{frame}

\begin{frame}{Liste de blocs}
  \emph{Worst  fit}   Utilise  le   plus  gros  bloc   disponible.  En
  comparaison de  \emph{Best fit}, il  ne permet pas d'avoir  des gros
  bloc  aussi important,  en revanche,  il limite  la perte  des petit
  espace.  Paradoxalement, c'est plutot une bonne stratégie.
  \\
  Exemple (\textbf{A}jout, \textbf{D}elete):
  \begin{center}
    \pgfimage[width=10cm]{pics/alloc-worstfit}
  \end{center}
   Problème inhérant à cet algorithme: la fragmentation
\end{frame}

\begin{frame}[fragile=singleslide]{Allocation binomiale}
  Allocation binômiale (buddy system)
  \begin{itemize}
  \item La mémoire disponible est regroupée en bloc de $2^n$ octets
  \item Ainsi, un  bloc d'ordre 2 fait 4 octets,  d'ordre 3, 8 octets,
    etc...
  \item On alloue toujours des bloc d'une taille de puissance de 2
  \item Si  aucun bloc de cette  taille est disponible,  on utilise un
    bloc d'ordre supérieur que l'on divise en deux
  \end{itemize}
  Exemple (\textbf{A}jout, \textbf{D}elete):
  \begin{center}
    \pgfimage[width=8cm]{pics/alloc-buddy}
  \end{center}
\end{frame}

\begin{frame}[fragile=singleslide]{Les pools de mémoires}
  Les pool de mémoires
  \begin{itemize}
  \item  Utilisé dans  les  application allouant  de grandes  quantité
    d'objets identiques
  \item On  crée des pools  de mémoire que  l'on découpe en  espace de
    taille égale
  \item On utilise une simple bitmap pour géré les bloc disponibles
  \item Algorithme le plus rapide et ayant le moins de frgamentation
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{\c{brk} vs \c{mmap}}
  Utilisation de \c{brk} ou de \c{mmap}
  \begin{itemize}
  \item \c{brk} garantie  un espace de mémoire continue  ce qui facile
    l'agrandissement
  \item \c{brk} ne permet pas de libérer un bloc au milieu du tas
  \end{itemize}
  Certains algorithme essaie de tirer  profit au maximum de mmap et de
  ne pas allouer de donnée à cheval sur deux pages de mémoires.
\end{frame}

\begin{frame}[fragile=singleslide]{GNU malloc}
  L'implémentation actuelle de  GNU-malloc utilise un mélange de
  ces principes en fontion de la taille du bloc demandé.
  \begin{itemize}
  \item Free-list + Best fit pour les tailles inférieure à 256 octets
  \item buddy-system pour les allocation entre 256o et 256Ko
  \item mmap pour le reste
  \end{itemize}
  %         Reprendre        les        exemples         de        cf:
  % https://umdrive.memphis.edu/blstuart/htdocs/excerpt3.pdf
\end{frame}

\subsection{Les garbages collectors}

\begin{frame}[fragile=singleslide]{Reference counters}
 Reference counting
    \begin{itemize} 
    \item  Un référence  counter et  un système  qui associe  à chaque
      objet (ou bloc de mémoire) de mémoire un compteur.
    \item Chaque fois que le  pointeur est copié dans une variable, le
      compteur  est incrémenté.  Si la  variable est  écrasée  par une
      nouvelle valeur ou est désallouée, on décrémente le compteur
    \item Si le compteur tombe à zero, on peut désallouer l'objet
    \item  Il est  possible  d'utiliser ce  système  en supplément  de
      l'allocation classique afin de vérifier qu'il n'y a pas d'erreur
      (si  le compteur tombe  à zero,  c'est une  fuite, si  on libère
      alors que le compteur est  supérieur à 1, il y a potentiellement
      un problème)
    \end{itemize} 
  \end{frame}

\begin{frame}[fragile=singleslide]{Reference counters}
  Plusieurs manière de l'implémenter:
  \begin{itemize}
  \item En C, on s'interdit les opérateurs d'affectation classiques et
    on  passe  par  des  fonctions qui  effecturons  l'affectation  et
    l'instrumentation.  Très contraingant, difficile de garantir qu'il
    n'y a pas d'autres affectation.  Il n'est pas possible de detecter
    la destruction d'un pointeur qui se trouve sur la pile.
  \item   En  C++,   il   est  possible   de  surcharger   l'opérateur
    d'affectation   pour  rendre  l'opération   transparentes.   Aussi
    appellé   \emph{smart  pointer}   dans   la  literature.    Classe
    \c{shared_ptr}            de            libboost.             (cf.
    \url{http://www.josuttis.com/libbook/cont/countptr.hpp.html})
  \item Dans une  machine virtuelle, ou dans un  langage de script, on
    controle  tous les  accès à  la mémoire,  donc ca  ne pose  pas de
    problème
  \end{itemize}
\end{frame}  

\begin{frame}[fragile=singleslide]{Reference counters}
  \emph{Conservative garbage collector}: Il est possible de scanner la
  mémoire  à  la recherche  de  pattern  ressemblant  à des  addresses
  (double mots > 1024).  Il est ainsi possible de retrouver combien de
  pointeur  pointent  sur  chaque  objets. Peuvent  générer  des  faux
  positifs par
  \begin{itemize} 
  \item Des pattern qui ressemble à des pointeur
  \item Des pointeurs internes (exemple: heritage d'objets en C++)
  \end{itemize} 
  % La  technique  est pas  utilisé comme  garbage
  % collector, mais  plutôt comme outils  d'instrumentation (Dans le
  % noyau Linux: kmemleak)
\end{frame}

\begin{frame}[fragile=singleslide]{Reference counters}
  \begin{itemize} 
  \item  Problème 1:  Dans  le cas  de  système multiprocesseurs,  les
    opérations  sur  les pointeur  doivent  être  atomique.  Or  cette
    opértion est relativement lente.
  \item Problème 2: les références circulaires
  \item L'ensemble des objets est un graphe orienté. Il est nécessaire
    de  faire  une  recherche  de  sous-graphe  indépendants.   Si  un
    sousgraphe  n'est référencé  par aucune  variable  globale (.data,
    .rss, etc...) ou locale (pile)
  \item  Il est théoriquement  nécessaire de  faire cette  recherche à
    chaque décrémention  du compteur de référence:  Lent et générateur
    de latence
  \item Lors de la décrémentation  on ajoute l'objet dans la liste des
    objets à vérifier et  on retarde la recherche (aka \emph{tri-color
      marking}: noir: referencé, gris: à vérifier, blanc: condamné).
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Reference counters}
  \begin{itemize} 
  \item La recherche de sous-graphe se fait alors:
    \begin{itemize} 
    \item Lors de l'allocation ou  à un autre moment définit (stop the
      world). Moins de perte de performance, mais toujours problème de
      latence
    \item  Dans  une  thread  séparée  (concurent).   Peut  créer  des
      problème  d'accès concurrents.  Par  forcement possible  sur les
      petit systèmes
    \item Incrémentale,  à chaque déréférencement ou  à chaque période
      de temps fixe, on parcourt une partie du graphe
    \end{itemize}
  \item On peut ajouter des heuristiques sur les objets à scanner. Par
    exemple: commencer par les objets les plus jeunes qui ont surement
    des  durées de  vie plus  courte  que les  vieux objets  (surement
    présent pour toute la durée du vie du programme).
  \end{itemize}
\end{frame} 


%\subsection{En espace noyau}
\subsection{Technique de debug mémoire}

\begin{frame}[fragile=singleslide]{dmalloc}
  \begin{itemize}
  \item  Enregistre les  bloc alloué  et les  bloc désalloués.  On est
    capbale de lister les blocs non désalloué en sortie de programme
  \item  Ajout de  garde-fou  avant  et après  les  blocs alloués  par
    malloc. Si lors  de la libération les garde-fous  ont été modifié,
    il y a un problème.
  \item  Ecriture   d'un  pattern  sur  la  mémoire   juste  après  sa
    libération. Permet  de garantir que  les donné lues après  un free
    seront corrompue.
  \item Lors de l'allocation, on vérifie que la mémoire a remplie avec
    le pattern. Si ca n'est pas le cas, une violation d'écriture s'est
    produite entre temps.
  \item  Permet aussi  de garantir  que le  code réinitialise  bien la
    mémoire après l'avoir alloué
  \end{itemize} 
% TODO: ajouter des schémas ou des exemple
\end{frame} 

\begin{frame}[fragile=singleslide]{Libefence, DUMA et kmemcheck}
  \begin{itemize} 
  \item Le principe est de s'aider de la MMU pour détecter les erreurs
    d'accès mémoire
  \item  La mémoire est  allouée avec  mmap. On  retire les  droits en
    lecture et en écriture sur le bloc de mémoire alloué.
  \item  A chaque  accès, en  lecture ou  écriture, une  exception est
    déclenché.
  \item Le système récupère la main, log l'accès et vérifie si l'octet
    sur lequel s'effectue l'accès est autorisé
  \item  Permet de détecter  l'erreur dès  qu'elle se  produit (plutot
    qu'à l'allocation suivante)
  \item Permet  de détecter un accès  en lecture sur  une addresse non
    initialisé
  \end{itemize}
% TODO: ajouter des schémas ou des exemples
\end{frame} 

\begin{frame}[fragile=singleslide]{Valgrind, kmemcheck, Mudflap}
  \begin{itemize} 
  \item  Utiliser  un  garbage  collector comme  instrumentation  pour
    vérifier la bonne utilisation de la mémoire
  \item Les différents algorithme de garbage collections s'appliquent
  \item   Kmemcheck:  Instrumentation   avec  un   garbage  collecteur
    conservatif dans le noyau
  \item Valgrind: Machine virtuelle JIT natif/natif
    \begin{itemize} 
    \item  Permet   d'instrumenter  tous  les  accès   à  la  mémoire:
      referencement, lecture et ecriture
    \item Permet de repérer les fuites ET les mauvais accès (comme DUMA)
    \item La detection de fuites ou de mauvais accès est immédiate
    \item Plus rapide que DUMA grace à la JIT
    \end{itemize} 
  \item Plutôt  que d'instrumenter le code durant  l'éxecution, il est
    possible de l'instrumenter durant la compilation
    \begin{itemize} 
    \item Mudflap (compilation avec \cmd{-fmudflap})
    \item Nécessite que toutes les bibliothèques soient instrumentées
    \end{itemize}
  \end{itemize}
  % TODO: ajouter des schémas ou des exemples
\end{frame} 

