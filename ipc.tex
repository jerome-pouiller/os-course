%
% This document is available under the Creative Commons Attribution-ShareAlike
% License; additional terms may apply. See
%   * http://creativecommons.org/licenses/by-sa/3.0/
%   * http://creativecommons.org/licenses/by-sa/3.0/legalcode
%
% Copyright 2012 Jérôme Pouiller <jezz@sysmic.org>
%

\part{Communication inter-tâches}

\section{Problèmatique des accès concurents}

\subsection{Protection des structures de données}

\begin{frame}[fragile]{Exemple de partage de données}
  Le partage de données entre les tâches posent les mêmes problèmes que
  le partage de données avec les interruptions

  Prennons deux tâches \c{f1} et \c{f2}:
  \begin{lstlisting}
int a = 0;
char t[255];
void f1() {
  t[a] = data1;
  a++;
}
void f2() {
  t[a] = data2;
  a++;
}
       \end{lstlisting}
\end{frame} 

\begin{frame}[fragile]{Exemple de partage de données}
Prennons le cas ou \verb+f1+ est préemptée par \verb+f2+:
  \begin{columns}
    \begin{column}{5cm}
      \begin{lstlisting}[showlines=true,emptylines=10]
t[a] = data1; // t[0];




a++;
// a = 2 maintenant
       \end{lstlisting}
     \end{column}
     \begin{column}{5cm}
      \begin{lstlisting}[showlines=true,emptylines=10,escapeinside=\{\}]

t[a] = data2; 
// t[0] est {é}cras{é}!
a++;
// a = 1 maintenant


       \end{lstlisting}
    \end{column}
  \end{columns}

  Au lieu d'écrire  les deux données l'une après  l'autre, la valeur de
  \verb+data1+ est perdue alors  que \verb+t[1]+ contiendra une valeur
  aléatoire.
\end{frame} 

\subsection{Protection des ressources matériel}

\begin{frame}[fragile]{Exemple de ressource partagée}
  Cas d'un  périphérique réseau avec des registres  mappés en mémoire.
  Le  registre  \c{0xABC0}  permet  de  placer la  donnée  à  envoyer.
  L'écriture  d'un 1  sur  le registre  \c{0xABC4} permet  d'effectuer
  l'envoi:
\begin{lstlisting} 
void send(int data) {
  *0xABC0 = data;
  *0xABC4 = 1;
}
  \end{lstlisting} 
\end{frame} 

\begin{frame}[fragile]{Exemple de ressource partagée}
  Etudions le cas de l'éxecution simultanée de cette fonction par deux
  tâches.  La première tâche appelle \c{send} avec \cmd{data = 42}:
  \begin{lstlisting} 
*0xABC0 = 42
  \end{lstlisting} 
  La  tâche est  préemptée.  La  seconde tâche  appelle  \c{send} avec
  \cmd{data = 10}:
\begin{lstlisting} 
*0xABC0 = 10
*0xABC4 = 1
\end{lstlisting} 
  \c{10} est envoyé. La tâche 1 reprend la main:
\begin{lstlisting} 
*0xABC4 = 1
\end{lstlisting} 
  \c{10} (au lieu de \c{42}) est de nouveau envoyé.\\[3mm]

  Ce cas  est aussi valable dans  le cas d'une  interruption (bien que
  plus rare dans la pratique).
\end{frame} 

\subsection{Réentrance}

\begin{frame}{Comment éviter le problème?}
  Nous devons élargir ce que nous avons précédement vu pour le partage
  d'informations avec les interruptions.

  Les problèmes d'accès concurrents se traduisent très souvent par des
  \emph{races  conditions}.   C'est à  dire  des problèmes  aléatoires
  produit par une séquence particulière d'évènements
  \begin{itemize} 
  \item   Les  \emph{races  conditions}   sont  souvent   difficiles  à
    reproduire et à identifier
  \item Les  \emph{races conditions} peuvent être latente  dans le code
    et se déclarer suite à une modification de l'environnement externe
  \item Une race condition coûte chère (difficulté de correction, peut
    potentiellement atterrir en production)
  \end{itemize} 
\end{frame}

\begin{frame}{Comment s'en protèger?}
  Comment s'en protèger?
  \begin{itemize} 
  \item  Ne  pas  utiliser  de  variables globales  ou  de  ressources
    partagées
  \item Utiliser des accès atomiques
  \item   Placer  des   accès   aux  ressources   partagée  dans   des
    \emph{sections critiques}
  \end{itemize} 
  Une  fonction  pouvant  être  appellée simultanénement  depuis  deux
  contextes de tâches différentes est dite \emph{réentrante}
\end{frame} 

\begin{frame}{Partage de ressources critiques} 
  Une ressource critique ne peut :
  \begin{itemize}
  \item être utilisée simultanément par plusieurs tâches
  \item être réquisitionnée par une autre tâche
  \end{itemize}
  Notion de section critique :
  \begin{itemize}
  \item  séquence  d'instructions pendant  lesquelles  on utilise  une
    ressource critique
  \item sans  problème dans le cas d'un  ordonnancement non préemptif,
    mais  c'est rarement  le cas  dans un  environnement temps  réel
  \item[⇒]  évaluation  du  temps  de réponse  très  difficile,  sinon
    impossible (abondante littérature !)
  \end{itemize}
\end{frame}

\subsection{Partage de ressource entre deux tâches: Fonctionnement d'un mutex}

\begin{frame}[fragile]{Fonctionnement d'un mutex}
  Nécessite une instruction assembleur  permettant un accès en lecture
  et en écriture  en une instruction: \\
  \texttt{test\_and\_set} affecte le registre d'état en fonction de la
  valeur  du registre  et affecte  la valeur  1 au  registre.  On peut
  développer la fonction \c{lock} à partir de là:
  \begin{lstlisting} 
void lock(mutex_t *m) {
  while (test_and_set(m))
    schedule();
}

void unlock(mutex_t *m) {
  m = 0;
  schedule();
}
  \end{lstlisting} 
\end{frame}

\begin{frame}[fragile]{Fonctionnement d'un mutex}
  Un peu mieux:
  \begin{lstlisting} 
void lock(mutex_t *m) {
  while (test_and_set(m)) {
    this_task.reason = m;
    this_task.state = stop;
    schedule();
  }
}

void unlock(mutex_t *m) {
  m = 0;
  foreach (i in tasks)
    if (i.state == stop && i.reason == m)
      i.state = run;
  schedule();
}
  \end{lstlisting}
\end{frame} 

\section{Problème liés aux partage de ressources}

\begin{frame}{Problèmes associés aux sections critiques}
  Voici les problèmes à prendre en considération lors de l'utilisation
  de sections critiques:
  \begin{itemize}
  \item Dead Lock
  \item Latence induite
  \item Inversion de priorité
  \end{itemize} 
\end{frame}

\subsection{Dead Lock}

\begin{frame}[fragile]{Dead lock}
  \begin{itemize} 
  \item Aussi appellé \emph{étreinte fatale}
  \item Deux tâches utilisent  deux ressources imbriquées dans l'ordre
    inverses
  \end{itemize} 
  \begin{columns}
    \begin{column}{5cm}
      Tache 1:
      \begin{lstlisting}[showlines=true,emptylines=10]
lock(m1);



lock(m2);
      \end{lstlisting} 
    \end{column}
    \begin{column}{5cm}
      Tache 2:
      \begin{lstlisting}[showlines=true,emptylines=10]

lock(m2);
// Deadlock ici:
lock(m1);

      \end{lstlisting} 
    \end{column}
  \end{columns}
  \begin{center}
    \input{pics/cs-deadlock.tex}
  \end{center}
\end{frame} 

\begin{frame}[fragile]{Dead lock}
  \textbf{Remarque:} \\
  Le code suivant:
  \begin{lstlisting} 
lock(m);
lock(m); 
  \end{lstlisting} 
  entraine un  \emph{double lock},  un type particulier  de \emph{Dead
    lock}
\end{frame} 

\begin{frame}[fragile]{Mutex dans une interruption}
  \textbf{Remarque:} \\
  Ne jamais utiliser de mutex dans une interruption.
  \begin{itemize} 
  \item Si  la ressource  est occuppée par  la tâche qui  vient d'être
    préemptée, le \texttt{lock()} s'éxécutera dans le même contexte
  \item[$\rightarrow$] Double lock
  \item De plus,  le blocage d'un mutex peut entrainer
    une  très  important latence  ce  qui  est  en contradiction  avec
    l'objectif de rester le minimum de temps dans une interruption
  \item[$\rightarrow$]  Règle  générale:   Il  ne  faut  pas  appeller
    \texttt{schedule} dans une interruption.
  \end{itemize} 
\end{frame} 

\section{Autres mécanismes de gestion d'accès concurrents}

\note{Pour chacun  des mécanisme,  donner les fonction  dasn plusieurs
  API,  faire  un exemple  ou  mieux,  donner  le code:  Posix,  Java,
  Xenomai, ucosII, vxWorks}

\subsection{Désactivation de l'ordonnanceur}

\begin{frame}{Désactivation de l'ordonnanceur}
  \begin{itemize} 
  \item On demande à l'OS de ne plus être préemptif
  \item Horriblement dangereux
  \item A  priori, à  ne jamais  utiliser sauf pour  faire des  cas de
    tests
  \end{itemize} 
\end{frame} 

\subsection{Sémaphore}

\begin{frame}{Sémaphore}
  \begin{itemize} 
  \item  Différence entre un  mutex et  un semaphore  binaire: presque
    aucune.
  \item Parfois le sémaphore  binaire est utilisé pour implémentéer le
    mutex.
  \item Toutefois,  d'un point de  vue sémantique, on  pourrait pemser
    que  le  mutex  permet  d'avoir  un morceau  de  code  mutuelement
    exclusif tandis que le sémaphore  est une section de code limité à
    une ressource.
  \item  Généralement,  les algorithmes  d'héritage  de priorité  sont
    implémentés sur les mutex mais pas sur les sémaphore.
%  \item  Notons  aussi  que  les  algorithmes  d'héritage  de  priorité
%    sont encore plus complexe sur les sémaphores
  \end{itemize} 
\end{frame} 

\subsection{Mutex réentrant}

\begin{frame}{Mutex Réentrant}
  \begin{itemize} 
  \item Idem  mutex, mais  si la même  tâche tente de  revérouiller le
    même mutex, le mutex est non-bloquant.
  \item Dans le cas  d'un mutex non-réentrant, ceci entraine forcement
    un dead-lock.
  \item Un sémaphore est maintenu pour connaitre le nombre de passage.
  \end{itemize} 
\end{frame} 

\begin{frame}[fragile=singleslide]{Les API}
  \begin{itemize} 
  \item   Posix:   \c{pthread_mutex_lock},   \c{pthread_mutex_unlock},
    \c{sem_wait}, \c{sem_post}
  \item Linux: \c{futex}
  \item Noyau Linux: \c{mutex_lock}, \c{mutex_unlock}
  \item  Xenomai:  \c{rt_sem_p},  \c{rt_sem_v},  \c{rt_mutex_acquire},
    \c{rt_mutex_release}
    \item Win32: \c{EnterCriticalSection}, \c{LeaveCriticalSection}
  \end{itemize} 
\end{frame} 


\subsection{R/W Lock}

\begin{frame}[fragile]{Read/Write Lock}
\note{\url{http://en.wikipedia.org/wiki/Readers-writers\_problem}}

Permet de limiter le phénomène  de latence en dimiminuant le nombre de
sections critiques.

Solution 1 (\emph{reader preference}):
\begin{columns}
  \begin{column} {5cm}
    \begin{lstlisting} 
void read_lock() {
  // mutex protege read_count
  lock(mutex);
  readcount++;
  if (readcount == 1)
    lock(w);
  unlock(mutex);
}
    \end{lstlisting} 
  \end{column}
  \begin{column} {5cm}
    \begin{lstlisting} 
void read_unlock() {
  lock(mutex);
  readcount--;
  if (readcount = 0)
    unlock(w);
  unlock(mutex);
}
void write_lock() {
   lock(w);
}
void write_unlock() {
  unlock(w);
}
    \end{lstlisting} 
  \end{column}
\end{columns}
\end{frame} 

\begin{frame}[fragile]{Read/Write Lock}
  Problème: un accès en écriture doit attendre que toutes les lectures
  soient terminées. Solution 2 (\emph{writer preference}):
  \begin{columns}
    \begin{column} {5cm}
      \begin{lstlisting} 
void read_lock() {
  lock(r);
  lock(mutex);
  readcount++;
  if (readcount == 1)
     lock(w);
  unlock(mutex);
  unlock(r);
  // r n'est pas bloque durant la lecture
}
       \end{lstlisting} 
     \end{column}
     \begin{column} {5cm}
       \begin{lstlisting} 
void read_unlock() {
  lock(mutex);
  readcount--;
  if (readcount == 0)
     unlock(w);
  unlock(mutex);
}
void write_lock() {
   lock(r);
   lock(w);
}
void write_unlock() {
  unlock(w);
  unlock(r);
}
      \end{lstlisting} 
    \end{column}
  \end{columns}
\end{frame} 

\begin{frame}[fragile=singleslide]{Les API}
  \begin{itemize} 
  \item  Posix:  \c{pthread_rwlock_wrlock}, \c{pthread_rwlock_rdlock},
    \c{pthread_rwlock_unlock}
  \item Xenomai: $\emptyset$
  \item  Win32: \c{AcquireSRWLockExclusive}, \c{AcquireSRWLockShared},
    \c{ReleaseSRWLockExclusive}, \c{ReleaseSRWLockShared}
  \end{itemize} 
\end{frame} 

\subsection{Rendez-vous ou barrier}
\begin{frame}[fragile]{Rendez-vous}
  Permet de synchroniser  deux tâches. La première tâche  arrivée à la
  barrière attend la seconde.
\begin{lstlisting} 
void init() {
  lock(m1);
  lock(m2);
}
\end{lstlisting}
Tâche 1:
\begin{lstlisting} 
  unlock(m1);
  lock(m2);
\end{lstlisting} 
Tâche 2:
\begin{lstlisting} 
  unlock(m2);
  lock(m1);
\end{lstlisting} 
\end{frame}

\begin{frame}[fragile=singleslide]{Les API}
  \begin{itemize} 
  \item Posix: \c{pthread_barrier_wait}
  \item Xenomai: $\emptyset$
  \item Win32: \c{EnterSynchronizationBarrier}
  \end{itemize} 
\end{frame} 

\subsection{Condition}

\begin{frame}[fragile]{Conditions}
  Peuvent  être   considérés  comme  des   \emph{rendez-vous}  à  sens
  unique. Si une tâche attend, elle est débloquée, sinon, aucun effet.
  Très utilisée pour le pattern des \cmd{work-thread}
  \begin{columns}
    \begin{column}{5cm}
      \begin{lstlisting} 
void init() {
  lock(m);
}

void wait() {
  lock(m);
}

void signal() {
  unlock(m);
  try_lock(m);
}
      \end{lstlisting}
    \end{column}
    \begin{column}{5.5cm}
      \begin{lstlisting} 
// broadcast debloque
// tous les waiters alors
// que signal en debloque
// uniquement un
void broadcast()  {
  // Plus complexe, il
  // faut un mutex par
  // waiters. 
}
      \end{lstlisting} 
    \end{column}
  \end{columns}
\end{frame} 

\begin{frame}[fragile=singleslide]{Les API}
  \begin{itemize} 
  \item    Posix:    \c{pthread_cond_wait},   \c{pthread_cond_signal},
    \c{pthread_cond_broadcast}
  \item Linux: \c{eventfd}, \c{select}, \c{read}, \c{write}
  \item Noyau Linux: \c{wait_event}, \c{wait_up}
  \item Xenomai: \c{rt_cond_signal}, \c{rt_cond_broadcast}, \c{rt_cond_wait}
  \item              Win32:              \c{WakeAllConditionVariable},
    \c{WakeConditionVariable}, \c{SleepConditionVariableCS}
  \end{itemize} 
\end{frame} 

\subsection{Buffer circulaire et Queue}

\begin{frame}[fragile]{Buffer circulaire et Queue}
  \begin{itemize} 
  \item  Précédement décrit dans  la section  ``Partage d'information
    avec les interruptions''
  \item Fonctionne aussi très bien entre les tâches
  \item Une  des rares structures  permettant d'être partagée à  la fois
    avec une interruption et des tâches
  \item Faire attention à l'allocation dynamique des objets
  \end{itemize}
\end{frame} 

\begin{frame}[fragile=singleslide]{Les API}
  \begin{itemize} 
  \item Posix/Linux: \c{mq_receive}, \c{mq_send}, \c{pipe}, \c{socket}
  \item Noyau Linux: \c{kfifo_put}, \c{kfifo_get}
  \item      Xenomai:     \c{rt_buffer_write},     \c{rt_buffer_read},
    \c{rt_queue_send}, \c{rt_queue_receive}
  \item Win32: \c{GetMessage}, \c{WaitMessage}
  \end{itemize} 
\end{frame} 


\subsection{Spin Lock, Mutex et désactivation des interruptions}

\begin{frame}[fragile]{Spin Lock, Mutex et désactivation des interruptions}
  Lorsque:
  \begin{itemize} 
  \item  Vos  sections critiques  font  intervenir  des  tâches et  des
    interruptions
  \item Votre problème ne concerne  pas un échange de données (et donc
    le buffer circulaire n'est pas une solution)
  \item Vous ne pouvez pas faire autrement
  \end{itemize} 
  alors,   vous  devez   combiner  les   trois   mécanismes  suivants:
  Désactivation des interruptions, Mutex et Spin Lock.

  Le point sur ces trois mécanismes:
  \begin{itemize} 
  \item  Si  une  ressource  est   partagée  entre  une  tâche  et  une
    interruption sur  le même coeur,  il est nécessaire  de désactiver
    les interruptions
  \item  Si une ressource  est partagé  entre deux  tâches sur  un même
    coeur, il est nécessaire d'utiliser un mutex
  \item Si  la ressource est  partagée avec un  autre coeur et  que le
    temps d'utilisation est court, utilisez un Spin Lock.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Spin Lock, Mutex et désactivation des interruptions}
  On pourrait imaginer un cas cummulant les trois contraintes:
  \begin{lstlisting} 
disable_interrupts()
mutex_lock(m)
spin_lock(s)
a++
spin_unlock(s)
mutex_unlock(m)
enable_interrupts()
  \end{lstlisting} 
  Globalement, évitez!
\end{frame} 

\subsection{Algorithmes non-bloquants}

\begin{frame}{Algorithmes non-bloquants}
  \begin{itemize} 
  \item Algorithme thread-safe n'utilisant pas de sections ciritques.
  \item Ces  algorithmes utilisent souvant  des instructions atomiques
    proposés par certains processeurs
  \item Par conséquent, ils sont peu portables
  \item Souvent utilisé dans les bases de données
  \end{itemize} 
\end{frame} 

\subsection{Read-Copy-Update (RCU)}

\begin{frame}{Read-Copy-Update (RCU)}
  Type d'algorithme non bloquant:
  \begin{itemize} 
  \item La lecture n'est pas bloquante
  \item On note le nombre de lecteurs
  \item Les modifications s'effectuent sur une copie de l'objet
  \item Les lectures suivante se font sur la nouvelle version de l'objet
  \item Lorsque  le dernier lecteur  a terminé, l'objet  d'origine est
    détruit. Seul subsiste la nouvelle version.
  \end{itemize} 
\end{frame}

\begin{frame}[fragile]{Exemple : Manipulation de listes} 
  \begin{center}
    \begin{lstlisting}[basicstyle=\ttfamily\scriptsize\color{colBasic},commentstyle=\scriptsize\itshape\color{colComments},numbers=none]
typedef struct {
   struct a_t a;
   int count_usage = 0;
   bool obsolete = false;
} rcu_t;
rcu_t *a = malloc(sizeof(rcu_t)); 
    \end{lstlisting}
  \end{center}
  \begin{columns}
    \begin{column}{5cm}
      \begin{lstlisting}[basicstyle=\ttfamily\scriptsize\color{colBasic},commentstyle=\scriptsize\itshape\color{colComments},numbers=none]
void read_a() {
  // lock:
  rcu_t *ptr = a;
  ptr->count_usage++;
  // do something with ptr;
  // unlock:
  ptr->count_usage--;
  if (ptr->obsolete && !ptr->count_usage)
    free(ptr);
}
      \end{lstlisting}
    \end{column}
    \begin{column}{5cm}
      \begin{lstlisting}[basicstyle=\ttfamily\scriptsize\color{colBasic},commentstyle=\scriptsize\itshape\color{colComments},numbers=none]
void write_a() { 
   struct rcu_t *a3 = a;
   struct rcu_t *a2 = malloc(sizeof(rcu_t));
   memcpy(a2, a);
   // modify a2;   
   a = a2;  
   a3->obsolete = true;
   if (!a3->count_usage)
      free(ptr);
}
      \end{lstlisting} 
    \end{column}
  \end{columns}
\end{frame} 

\subsection{Mémoire partagée}

\begin{frame}[fragile=singleslide]{La mémoire partagée}
  \begin{itemize} 
  \item Utilise  le MMU pour partager  une page de  mémoire entre deux
    processus
  \item dans  cette page de  mémoire, il est possible  d'appliquer les
    mécanisme        de       synchronisation        des       threads
    (\man{pthread\_mutexattr\_getpshared(3)})
  \item 
  \end{itemize} 
\end{frame} 

\begin{frame}[fragile=singleslide]{Les API}
  \begin{itemize} 
  \item Posix: \c{shm_open}, \c{mmap}, \c{ftruncate}
  \item Xenomai: \c{rt_heap_create}, \c{rt_heap_bind}
  \item     Win32:     \c{CreateFileMapping},     \c{OpenFileMapping},
    \c{MapViewOfFile}
  \end{itemize} 
\end{frame} 

\subsection{Les signaux}

\begin{frame}[fragile=singleslide]{Les signaux}
  \begin{itemize}
  \item Idée issue de l'immitation des interruption sur l'OS
  \item +/- spécifique aux systèmes Posix
  \item L'histoire a rendu l'API un peu bordélique
  \item     \man{sigaction(2)},     \man{signal(7)},    \man{kill(2)},
    \man{kill(1)}, \man{sigqueue(3)}
  \item Il existe 64 signaux sous Linux
  \item Certain  signaux peuvent  être envoyé à  partir de  la console
    (c'est  le   noyau  qui  traduit   les  touches  en   signaux,  cf
    \man{stty(1)})
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Les signaux}
  \begin{itemize}
  \item  Les  signaux  <  32  sont nommés  et  ont  une  signification
    particulière:
    \begin{columns}
      \begin{column}{3cm}
        \begin{itemize} 
        \item 1: HUP
        \item 2: INT (\c{^C})
        \item 3: QUIT (\c{^\\})
        \item 4: ILL
        \item 5: TRAP
        \item 6: ABRT
        \item 7: BUS
        \item 8: FPE
        \end{itemize}
      \end{column}
      \begin{column}{3cm}
        \begin{itemize} 
        \item 9: KILL
        \item 10: USR1
        \item 11: SEGV
        \item 12: USR2
        \item 13: PIPE
        \item 14: ALRM
        \item 15: TERM
        \item 16: STKFLT
        \end{itemize}
      \end{column}
      \begin{column}{3cm}
        \begin{itemize} 
        \item 17: CHLD
        \item 18: CONT
        \item 19: STOP (\c{^Z})
        \item 20: TSTP
        \item 21: TTIN
        \item 22: TTOU
        \item 23: URG
        \item 24: XCPU
        \end{itemize}
      \end{column}
      \begin{column}{3cm}
        \begin{itemize} 
        \item 25: XFSZ
        \item 26: VTALRM
        \item 27: PROF
        \item 28: WINCH
        \item 29: POLL
        \item 30: PWR
        \item 31: SYS
        \end{itemize}
      \end{column}
    \end{columns}
    \vspace{2ex}
  \item Il existe  un comportement par défaut pour  chaque signal (fin
    de la tâche, suspension, coredump, ignore)
  \item Il  est possible d'associer ces propres  fonctions aux signaux
    (sauf quelques uns)
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Signaux Temps Réels}
\begin{itemize} 
\item Les signaux > 32 sont dit \emph{temps-réel}.
    \begin{itemize}
    \item Plusieurs signaux RT peuvent être en attente
    \item Garantie que les signaux arrivent dans l'ordre dans lesquels
      ils ont été envoyés
    \item Possibilité de passer des valeurs en arguments
    \end{itemize} 
  \item Tombent en désuétude. Remplacés par des \emph{file descriptor}:
    \begin{itemize} 
    \item \man{signalfd(2)}
    \item \man{eventfd(2)}
    \item \man{timerfd\_create(2)}
    \item \man{inotify(7)}
    \end{itemize}  
  \end{itemize} 
\end{frame}




