%
% This document is available under the Creative Commons Attribution-ShareAlike
% License; additional terms may apply. See
%   * http://creativecommons.org/licenses/by-sa/3.0/
%   * http://creativecommons.org/licenses/by-sa/3.0/legalcode
%
% Created: 2011-08-14 17:43:38+02:00
% Main authors:
%     - Jérôme Pouiller <jezz@sysmic.org>
%

\part{Le multitâches}

\begin{frame}
\partpage
\end{frame}

\begin{frame}
\tableofcontents[currentpart]
\end{frame}

\section{Le temps partagé}

\begin{frame}{Concurrence}
  \begin{itemize}
  \item   Des   tâches   concurrentes   sont   des   tâches   exécutées
    séquentiellement sur un seul processeur en entrelaçant l'exécution
    de chaque tâches
  \item  Pour les tâches,  le temps  partagé est  transparent.  Chaque
    tâche à l'impression d'avoir le CPU pour elle-seule
  \item  On  trouvera aussi  le  terme  de  \emph{multitâches} ou  de
    \emph{temps partagé}
  \end{itemize}
\end{frame}

\begin{frame}{Concurence}
   La programmation concurrente N'EST  PAS de la programmation parallèle
  (même les système multicoeurs sont souvent concurrent et parallèle):
  \begin{center}
    \pgfimage[width=10cm]{pics/concurentVsParallel}
  \end{center}
\end{frame}

\begin{frame}[fragile]{Programmation multitâche}
\begin{lstlisting}
#include <unistd.h>

int main() {
  int r;

  r = fork();
  if (r < 0) {
     // Error
  } else if (r > 0) {
    // Parent
  } else /* r == 0 */ {
    // Child
  }
}
\end{lstlisting}
\end{frame}

\begin{frame}{Concurrence}
  Migration d'un système avec gestion asynchrone des interruptions vers
  un système multitâches:
  \begin{center}
    \pgfimage[width=10cm]{pics/model_multitask}
  \end{center}
\end{frame}

\begin{frame}{Tâches concurrentes}
  Pour les  systèmes plus complexes ou pour  facilité la réutilisation,
  un   système   multitâche   est   plus   approprié   qu'un   système
  \emph{Foreground/Background}.
  \begin{itemize}
  \item Facilite la gestion des évènements
  \item Permet de prioriser les traitements
  \end{itemize}
  \note{Parler  des différentes  états des  tâches ici.  Il  manque un
    slide avec du code.}
\end{frame}

\begin{frame}{Etats des tâches}
  \begin{center}
    \input{pics/task_states}
  \end{center}
\end{frame}


\subsection{Changement de contexte}

\begin{frame}{Le changement de contexte}
  Chaque tâche possède une pile en mémoire. Une liste globale contient:
  \note{Faire un schéma}
  \begin{itemize}
  \item les états de toutes les tâches
  \item l'emplacement de la pile en mémoire
  \item le contexte d'exécution, c'est-à-dire une sauvegarde des registres
  \end{itemize}
  Lors du changement de contexte
  \begin{itemize}
  \item  on  sauvegarde  le   contexte  de  la  tâche  précédente,  en
    particulier son pointeur de pile et son pointeur d'instruction
  \item on restaure le contexte de la nouvelle tâche
  \item on restaure le pointeur d'instruction
  \end{itemize}
  Dans la  pratique, il y a  des petites subtilités  dépendantes de la
  manière dont le changement de contexte à été amené.
\end{frame}

\begin{frame}{Le changement de contexte}
  \begin{center}
    \pgfimage[width=7cm]{pics/context_switch}
  \end{center}
\end{frame}

\begin{frame}{Multitâche non-préemptif}
  Le changement de contexte  peut-être volontaire par les tâches. Dans
  ce   cas,  la   tâche   ayant  terminé   son  traitement   appellera
  explicitement   la  fonction   \emph{schedule}   qui  effectuera   la
  changement  de   contexte.  le  système  est   dit  non-péemptif  ou
  multitâche collaboratif.
\end{frame}

\begin{frame}{Multitâche non-préemptif}
  Ce type  de système implique une  latence difficilement quantifiable
  entre un évènement et sont traitement:
  \begin{center}
    \pgfimage[width=7cm]{pics/preemptive-no}
  \end{center}
\end{frame}

\begin{frame}{Multitâche non-préemptif}
  \begin{enumerate}
  \item  Une tâche  non prioritaire  est en  cours d'exécution  et est
    interrompue par un évènement (une IRQ)
  \item L'ISR est appellé
  \item Le traitement  l'IRQ rend une tâche de  haute priorité prête à
    être exécutée
  \item  A  la fin  de  l'ISR,  le système  rend  le  CPU  à la  tâche
    non-prioritaire
  \item Quand  la tâche non-prioritaire termine  sont traitement, elle
    appelle \texttt{schedule}
  \item L'ordonnanceur donne la main à la tâche de forte priorité
  \item La tâche de haute priorité peut (enfin) s'exécuter
  \end{enumerate}
\end{frame}

\begin{frame}{Multitâche préemptif}
  Un  système  multitâche préemptif  va  être  capable  de changer  de
  contexte lors des interruptions:
  \begin{center}
    \pgfimage[width=10cm]{pics/preemptive-yes}
  \end{center}
\end{frame}

\begin{frame}{Multitâche préemptif}
  \begin{enumerate}
  \item  Une tâche  non prioritaire  est en  cours d'exécution  et est
    interrompue par un évènement (une IRQ)
  \item L'ISR est appelée
  \item Le traitement  l'IRQ rend une tâche de  haute priorité prête à
    être exécutée
  \item A la fin de l'ISR, le système appel le scheduler
  \item Le scheduler donne la main a la tâche de haute priorité
  \item  Quand  la tâche  prioritaire  termine  sont traitement,  elle
    appelle \texttt{schedule}
  \item   Vu  qu'il  n'y   a  plus   tâche  prioritaire   à  exécuter,
    l'ordonnanceur redonne la main à la tâche de faible priorité
  \end{enumerate}
\end{frame}

\begin{frame}{Le changement de contexte sur interruption}
  \begin{center}
    \pgfimage[width=10cm]{pics/interuption-2}
  \end{center}
\end{frame}

\begin{frame}[fragile]{Round robin}
  Examinons  le cas de  deux tâches  de priorité  égales n'effectuant
  jamais de relanchement volontaire:
  \begin{lstlisting}
task1() {
  for(;;) ;
}
task2() {
  for(;;) ;
}
  \end{lstlisting}
\end{frame}

\begin{frame}[fragile]{Round robin}
  Dans ce cas, si aucune interruption ne se produit, la première tâche
  à avoir pris la main ne la rendra jamais. Afin de reprendre la main,
  on  utilise une  interruption  d'horloge.  Celle-ci  garanti que  le
  système  pourra périodiquement  reordonnancer les  tâches.  La période
  l'horloge utilisée est appelée quantum de temps ou HZ dans le cas de
  Linux.

  Dans   ce  cas-ci,   l'ordonnanceur  devra   donner  une   période  à
  \emph{task1} puis une période à  \emph{task2} et ainsi de suite.  Ce
  comportement s'appelle \emph{Round-Robin} ou \emph{Tourniquet}.
  \begin{center}
    \input{pics/round_robin}
  \end{center}
\end{frame}


% TODO: Section à etoffer. Il faut tout détailler
\section{Pagination de la mémoire}

\begin{frame}{La MMU}
  Le temps partagé  permet de simuler que chaque tâche  est la seule à
  utiliser le CPU.

  En revanche, la mémoire est partagée entre les tâches. Ainsi, si une
  tâche A écrit par erreur sur l'espace d'une tâche B:
  \begin{itemize}
  \item  La tâche B plante
  \item  Le problème est complexe à trouver
  \item Il  n'y a  aucune moyen  pour empêcher la  tâche A  de faire
    cette action.
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{La segmentation}
  \begin{itemize}
    \item Premier mécanisme de protection
    \item On associe à des zone de mémoire des droits
    \item Indique au CPU  que certaines zone (appelés \emph{segments})
      de la mémoire ne doivent pas  être écrite ou ne doivent pas être
      exécutées
    \item Permet  de séparer les  données accessible en  écriture, des
      données accéssible en lecture seule, du code.
    \item Chaque section d'une binaire ELF est  chargé dans un
      segment séparé
    \item  De  nos  jours,  cette  méthode est  très  souvent  utilisé
      conjointement avec la pagination
  \end{itemize}
\end{frame}

\begin{frame}{La pagination et la MMU}
  Les CPU  modernes intègrent  un composant appelé  MMU (\emph{Memory
    Management Unit}):
  \begin{itemize}
  \item  Unité de translation d'adresses mémoire
  \item  On parle d'adresses physiques et virtuelles
  \item Lorsque le  MMU est actif (cas nominal),  toutes les adresses
    du code assembleur sont des adresses virtuelles
  \item  Il est  possible de  configurer le  MMU avec  une instruction
    spéciale et  en lui  donnant un pointeur  sur un tableau  (dans la
    pratique,  il s'agit  plutôt d'un  arbre) associant  les adresses
    physiques et les adresses virtuelles
  \end{itemize}
\end{frame}

\begin{frame}{La pagination et la MMU}
  \begin{center}
    \includegraphics[height=6cm]{pics/linearaddress}
  \end{center}
\end{frame}

\begin{frame}{La MMU (2)}
  \begin{itemize}
  \item  Il est  possible de  changer les  associations  simplement en
    chargeant un pointeur sur une autre table
  \item On  défini alors une table  par tâche.  Lors  du changement de
    contexte, on change aussi de table
  \item Le CPU possède alors deux modes:
    \begin{itemize}
    \item  Utilisateur
    \item  Superviseur
    \end{itemize}
  \item  Seul  le  mode  superviseur  (l'OS) permet  de  modifier  les
    associations de la MMU
  \end{itemize}
\end{frame}

\begin{frame}{La MMU (2)}
  \begin{center}
    \includegraphics[height=6cm]{pics/img9}
  \end{center}
  \note{Nous verrons  par la suite comment passer  du mode superviseur
    au  mode utilisateur  et vice  versa\\}
  \note{Vérifier  sur wikipedia  ``adresse  virtuelle'' et  ``mémoire
    paginée''}
\end{frame}

\begin{frame}{La MMU - gestion des exceptions}
  Toutes les adresses physiques ne sont pas associées à des adresses
  virtuelles
  \begin{itemize}
  \item Une tâche A ne peut pas accéder à la mémoire d'une tâche B
  \item Protection contre les erreurs de programmation
  \item Permet d'assurer la sécurité des systèmes multi-utilisateurs
  \item Une tâche à l'impression d'avoir toute la mémoire pour elle
  \end{itemize}
\end{frame}

\begin{frame}{La MMU - gestion des exceptions}
  Toutes  les  adresses  virtuelles  ne  sont  pas  associées  à  des
  adresses physiques
  \begin{itemize}
  \item  Lorsqu'une tâche  accède à  une adresse  non  associée.  Une
    exception est déclenchée.  Cela permet à l'OS de reprendre la main
    et de traiter l'erreur (souvent en tuant la tâche fautive)
  \item Lorsqu'une tâche souhaite allouer de la mémoire
    \begin{itemize}
    \item  La tâche demande à l'OS
    \item  L'OS choisi  un (ou  plusieurs) blocs  de  mémoire physique
      libres
    \item L'OS marque le bloc comme appartenant à la tâche
    \item  L'OS choisi un  espace d'adresse  virtuelle où  associer le
      bloc de mémoire
    \item L'OS met à jour la MMU
    \item L'OS retourne l'adresse virtuelle
    \item cf. \man{sbrk(2)} et \man{mmap(2)}
    \end{itemize}
  \end{itemize}
\end{frame}

\subsection {Passage en mode superviseur}

\begin{frame}{Passage en mode superviseur}
  Un processus utilisateur ne peut pas passer en mode superviseur.

  Comment passer en mode superviseur?
  \begin{itemize}
  \item Lorsqu'une interruption/exception est déclenchée
  \end{itemize}

  Comment appeler une fonction du système?
  \begin{itemize}
  \item  Les  tâches ont  besoin  de  faire  des demandes  au  système
    (exemple: allouer de la mémoire)
  \item Ces fonctions système s'appellent des \emph{appels système} ou
    \emph{syscall} (section 2 des pages de man)
  \item  Elles ont  très  peu de  points  communs avec  les appels  de
    fonctions classiques
  \item   Chaque  \emph{syscall}   est   associé  à   un  numéro   (cf
    \file{sys/syscall.h} \file{asm/unistd\_32.h}, \man{syscalls(2)})
  \end{itemize}

\end{frame}

\begin{frame}{Passage en mode superviseur}
  Pour utiliser les \emph{appels systèmes} (cf. \man{syscall(2)}):
  \begin{itemize}
  \item On place les arguments sur la pile
  \item On place le numéro de l'interruption sur la pile
  \item On déclenche une interruption logicielle (\c{int 0x80})
  \item  Le  CPU  passe  en  mode  superviseur  et  appelle  l'ISR  de
    l'interruption
  \item L'OS prend  la main, regarde le premier élément  de la pile et
    appelle la fonction correspondante (\file{asm-generic/unistd.h})
  \end{itemize}
  Il  existe maintenant des  instructions spéciales  sur les  CPU pour
  optimiser    les    \emph{syscall}    (instructions    \c{sysenter},
  \c{sysexit})
\end{frame}

\section{Optimisation possible grâce à la MMU}

\subsection{Les segfaults}

\begin{frame}{Gestion de la mémoire}
  Gestion des droits sur les pages
  \begin{itemize}
  \item    Il    est     possible    d'affecter    des    droits    en
    lecture/écriture/exécution sur les pages gérées par la MMU
  \item Si la tâche essaye d'écrire sur une page contenant des données
    constantes, il s'agit d'un bug et une exception est levée
  \item  On garantie  que  les pages  \emph{read-only}  ne seront  pas
    modifiées
  \item Une page contenant des données constantes (donné ou code) peut
    être mappée dans plusieurs tâches différentes
  \item En retirant les droits  en exécution sur les pages de données,
    on améliore la sécurité du système (impossible d'exécuter une page
    contenant des données)
  \item Une  page accessible  en écriture peut  être mappée  dans deux
    tâches afin de leur permettre de partager des données
  \end{itemize}
\end{frame}

\begin{frame}{La MMU - gestion des exceptions}
  Le MMU permet à l'OS de mieux utiliser la mémoire:
  \begin{itemize}
  \item  L'OS peut  donner  des espaces  d'addressage virtuel  contigu
    alors que la mémoire physique est fractionnée
  \item Le système n'alloue jamais la plage $[0, 1024]$
    \begin{itemize}
    \item Cela donne une plage de valeurs spéciales (ex: NULL)
    \item Ainsi, lors du debug, vous êtes certains qu'un pointeur $\in
      [0, 1024]$ est non valide
    \item En dehors des pointeurs,  les nombres que l'on manipule sont
      très  souvent <  1024.   Ce système  nous  permet de  rapidement
      repérer des casts abusifs entre des integers et des pointeurs
    \end{itemize}
  \item ``Sun a inventé le SegFault''
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Context Swap, cache et MMU}
  \begin{itemize}
  \item  Le  MMU est  associé  à  un  cache appelé  TLB  (Translation
    lookaside buffer)
  \item  Lorsqu'une  tache tente  d'accéder  à  une  adresse, le  MMU
    regarde  le TLB,  si il  trouve l'adresse,  elle  est directement
    traduite (\emph{TLB hit})
  \item  Sinon,   il  est  nécessaire   de  traverser  la   table  des
    pages.  Cette  opération  peut   couter  une  centaine  de  cycles
    d'horloge.
  \item Il existe deux mode de fonctionnement du TLB:
    \begin{itemize}
    \item Automatique: Le MMU parcours automatique la table des pages
    \item  Manuel: Une  exception  est déclenchée.   L'OS parcourt  la
      table, met à jour le TLB et rend la main.
    \end{itemize}
  \item Dans  le cas d'un  système multiprocessus, le  mappping change
    lorsque l'on passe d'une tache à l'autre
    \begin{itemize}
    \item  Certains systèmes nécessitent  d'invalider la  totalité du
      TLB
    \item  D'autre permettent  d'associer  un numéro  de  tâche à  une
      entrée  du TLB. Ainsi,  lorsque la  tâche précédente  reprend la
      main, ses entrées dans le TLB sont encore valides
    \end{itemize}
  \end{itemize}
\end{frame}

\subsection{Overcommit}

\begin{frame}{Overcommit}
  Principe de l'overcommit:
  \begin{itemize}
  \item Une tâche demande une allocation
  \item Le système  enregistre la demande dans le  Memory Manager mais
    ne modifie pas le MMU
  \item  Le  système  indique   à  la  tâche  que  l'allocation  s'est
    correctement déroulée
  \item Lorsque la tâche accède à cette page, une exception est levée
  \item Le système reprend la main
  \item Il remarque qu'il avait promis cette page
  \item Il alloue un bloc physique et met à jour la MMU
  \item Il rend la main à la tâche
  \item Tout est transparent pour la tâche
  \end{itemize}
  Voir             \file{/proc/sys/vm/overcommit\_memory}            et
  \file{/proc/sys/vm/overcommit\_memory}
\end{frame}

\subsection{La Swap}

\begin{frame}{La swap}
  \begin{itemize}
  \item La  swap est une partie  de la mémoire de  masse utilisée pour
    stockée des données de la mémoire RAM
  \item Utilisation de la Swap:
  \begin{itemize}
  \item Lorsque le système n'a plus assez de mémoire
  \item Il choisit une page physique qu'il copie sur le disque dur
  \item  Il  supprime  la  page   de  la  MMU  de  la  (les)  tâche(s)
    concernée(s)
  \item Lorsque la tâche accède à la page supprimée, une exception est
    levée
  \item Le système récupère alors la page sur le disque
  \item Le système réécrit la page dans la mémoire physique
  \item Il associe l'adresse virtuelle demandée avec la nouvelle page
    physique
  \item L'OS rend la main à la tâche
  \item Tout est transparent pour la tâche
  \end{itemize}
\item Voir \file{/proc/sys/vm/swappiness}
\end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Compression de la mémoire}
  Compression de la mémoire
  \begin{itemize}
  \item  Mécanisme remplaçant  la  swap sur  les  système dépourvu  de
    mémoire  de   masse  (ou  mémoire  de  masse   limités  en  nombre
    d'écritures)
  \item  Au lieu  de copier  les page  que un  disque, les  pages sont
    compressés
  \item Mis  à part les  heuristiques utilisée, le  fonctionnement est
    identique
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{\c{mlock}                     et
  \c{mlockall}}
  \begin{itemize}
  \item Les  fonctions systèmes \c{mlock}  et \c{mlockall}
    permettent  de  demander  à  Linux  de garder  des  pages  (ou  la
    totalité en mémoire)
  \item Elle empêche ainsi l'utilisation de l'overcommit et du swap.
  \item  Il ne  faut pas  oublier d'allouer  une pile  suffisante avant
    d'appeler \c{mlockall}
    \note{Ajouter du code à ce sujet}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Utilisation de \c{mlock}}
\begin{lstlisting}
#include <sys/mman.h>

void alloc_stack_1k() {
  char t[1024];
}

int main() {
  alloc_stack_1k();
  mlockall(MCL_CURRENT | MCL_FUTURE);
}
\end{lstlisting}
\end{frame}

\subsection{Gestion par l'OS}

\begin{frame}[fragile]{Mapping de l'OS}
  \begin{itemize} 
  \item Une interruption  peut avoir lieu depuis n'importe quel processus
  \item Lors d'une interruption (ou  d'un appel système), le CPU passe
    en mode  superviseur, mais  le mapping mémoire  reste celui  de la
    tâche d'origine
  \item Pour  des raison de performance,  il est préférable  de ne pas
    faire  de  changement de  mapping  durant  l'éxecution de  l'appel
    système (ou de l'interruption)
  \item Le noyau se trouve donc  dans une zone interdite en accès mais
    toujours mappé au même endroit quelquesoit la tâche.
  \item Afin  de simplifier les opérations  d'acces aux entrée/sortie,
    le  mapping du  noyau est  dit 'flat  mapping'. C'est  à  dire que
    chaque addresse  virtuelle correspond à une adresse  physique + un
    offset  constant (par  défaut  sur PC:  0xC0000000,  c'est à  dire
    3Go). Cet espace s'apelle ``low memory''
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Mapping de l'OS}
  \begin{itemize} 
  \item Le  noyau peut  allouer de  la mémoire en  dehors de  la ``low
    memory'' (en  ``high memory''), mais il devrat  peut-être faire un
    changement de mapping mémoire pour y accéder.
  \item Le noyau  réserve la ``low memory'' pour  son usage. Une tache
    ne peut pas allouer de la mémoire dans cette zone.
  \item Par défaut sur Linux 32bits, l'espace est partagé en 1Go / 3Go
  \item Sur un système possédant  moins de 1Go de mémoire physique, le
    kernel peut accéder à tout  l'espace physique à partir de la ``low
    memory''.  Sinon,  il peut potentiellement  y avoir des  pertes de
    performances lors  de l'accès par  le noyau à la  mémoire physique
    supérieure au premier Gigaoctet.
  \item Une application demandant  plus de 3Go d'espace virtuelle peut
    ne pas fonctionner
  \item La solution: passer en 64bits.
  \end{itemize} 
\end{frame}

\subsection{Mapping des fichiers en mémoire}

\begin{frame}{Gestion de la mémoire}
  Simplification des accès au IO
  \begin{itemize}
  \item   La  tâche   demande  de   mapper  un   fichier   en  mémoire
    (\man{mmap(2)})
  \item cf. \file{/proc/*/maps}
  \item  Le système  alloue un  espace d'adressage  virtuel égal  à la
    taille du fichier
  \item Le fichier en lui même n'est pas chargé en mémoire
  \item Lorsque la  tâche accès à un espace  du fichier, une exception
    est levée et la page demandée est chargée de manière transparente
  \item cf. champ RSS de \file{/proc/*/smaps}
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Les pages dirty}
  La marque \emph{Dirty}
  \begin{itemize}
  \item Quelques  soit la demande de l'utilisateur,  le système marque
    les page associés à des fichier comme Read-Only.
  \item  Ainsi, lorsque  la tâche  tente  d'écrire dans  la page,  une
    exception est levée
  \item  La  page est  alors  marquée  \emph{dirty}  , les  droits  en
    écriture sont données et le système rend la main
  \item Le système sait que  cette page devra être synchronisé avec la
    mémoire de masse
  \item Le système peut repousser cette opération
  \item Lorsque  le système  a synchroniser la  page, il la  marque de
    nouveau Read-Only
  \item cf. champ Dirty de \file{/proc/*/smaps}
  \end{itemize}
  Ce mécanisme est complémentaire à l'utilisation de la Swap. :
  \begin{itemize}
  \item Lorsque  le système  à besoin de  mémoire, il peut  écrire les
    pages modifiées sur le disque et décharger la page de la mémoire
  \end{itemize}
  cf.    champ   \emph{buffer}   et   \emph{cache}  de   la   commande
  \man{free(1)}
\end{frame}

\begin{frame}[fragile=singleslide]{Partage de page}
  \begin{itemize}
  \item Une  tâche peut demander explicitement de  partager un segment
    de mémoire avec une autre page.
  \item Il  suffit de  faire pointer deux  adresse virtuelle  vers la
    même adresse physique
  \item Lorsqu'un fichier (ou une  section du fichier) est déjà chargé
    en  mémoire,  le  système  ne  duplique  pas  la  page.  Elle  est
    automatiquement marqué comme page partagée
  \item Si  une des  tâche tente d'y  accéder en écriture,  le système
    duplique la  page juste  avant l'accès en  écriture (et  marque la
    nouvelle page comme dirty).
  \end{itemize}
\end{frame}

\subsection{Mapping de périphérique en mémoires}

\begin{frame}{Gestion de la mémoire}
  Sécurisation des accès aux périphériques
  \begin{itemize}
  \item  Lorsque  les  registres  des  périphériques  sont  mappés  en
    mémoire, on utilise la MMU pour y accéder
  \item Il  est possible d'autoriser  l'accès à un périphérique  à une
    tâche sans lui donner d'accès au reste du système
  \item Un système utilisant  très fortement cette méthode est appelé
    micro-kernel
  \item La méthode est peu  utilisée sous Linux (on utilisera \c{mmap}
    sur \file{/dev/mem})
  \item cf. \man{ioperm(2)}
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{\emph{mmap} sur des filedevice}
  \begin{itemize}
  \item Il est possible de  mapper en mémoire des fichier périphérique
    (avec \man{mmap(2)})
  \item  L'interprétation  de  cette  de  demande  est  laissée  à  la
    discrétion du driver
  \item Dans certains cas, ca n'a pas de sens: un port série
  \item \file{/dev/mem}:  permet de mapper toute la  mémoire physique sur
    une adresse virtuelle
  \item   \file{/dev/video0}   (Webcam):   L'espace  de   mémoire   mappé
    représentera une frame.
  \item  \file{/dev/fb0} (Frame buffer):  L'espace de  mémoire représente
    l'écran
  \item Ce mécanisme vite les recopie de données
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Architecture d'un DMA}
  Un DMA \emph{Direct Memory Access}:
  \begin{itemize}
  \item Il s'agit d'un mécanisme matériel.
  \item  Il   doit  être  supporté   par  le  contrôleur   de  mémoire
    (comprenant le MMU), le périphérique (ou le bus) et par l'OS
  \item Le  driver donne au périphérique  une adresse  (physique) où
    écrire
  \item Le périphérique demande un canal DMA au contrôleur
  \item Dans le cas d'un PC, c'est le contrôleur PCI (le northbridge)
    qui joue le rôle de contrôleur
  \item  Le  périphérique écrit/lit  ses  données  en  passant par  le
    contrôleur de mémoire mais sans passer par le CPU
  \item Le périphérique  déclenche une interruption lorsque l'ensemble
    des données sont écrites/lues
  \end{itemize}
  Le  driver peut  décider  de  mapper la  zone  DMA directement  dans
  l'espace d'adressage de la  tâche utilisateur. Avec ce mécanisme, il
  est possible de traiter de grande quantité de données sans copie.
\end{frame}

\begin{frame}[fragile=singleslide]{Fonctionnement    d'un    récepteur
    satellite haut de gamme}
  \begin{itemize}
  \item Un  récepteur satellite  (ou IP-TV) est  principalement composé
    d'un démodulateur/démultiplexeur et d'une carte graphique.
  \item Ces deux périphérique sont équipés de DMA
  \item  On  alloue  une  zone  de  mémoire  suffisamment  grande  pour
    réceptionner quelques images (2 - 3 au moins)
  \item L'OS passe l'adresse de cette zone au démultiplexeur
  \item Des que le multiplexer à fini d'écrire une frame, il déclenche
    une interruption (et  continue d'écrire la suite dans  la suite du
    DMA)
  \item L'OS  reprend la main. Il  passe l'adresse de cette  zone à la
    carte graphique.
  \end{itemize}
  Il est ainsi possible de transférer de grande quantité de données en
  limitant l'utilisation  du CPU (et  les risque de problème  de temps
  réel)
\end{frame}

\section{Threads et Processus}

\begin{frame}{Threads}
  Thread versus Processus
  \begin{itemize}
  \item On appelle les  tâches ayant des contextes mémoires différents
    des \emph{Processus} (cf. \man{fork(2)})
  \item  Il est  possible  d'exécuter plusieurs  tâches  dans un  même
    contexte mémoire
  \item  Ces  tâche sont  appelées  \emph{threads} ou  \emph{processus
      légers} (cf. \man{clone(2)})
  \item Le fonctionnement  est alors identique au mode  sans MMU, avec
    les mêmes défauts et avantages:
    \begin{itemize}
    \item Pas  de protection contre  les erreurs de  programmation des
      autres threads
    \item Partage de l'information simplifiée
    \item Passage d'une thread à une autre beaucoup plus rapide
    \end{itemize}
  \end{itemize}
  \note{Attention au latence lors de l'allocation, et du swap}
\end{frame}

\begin{frame}[fragile]{Utilisation de processus}
\begin{lstlisting}
#include <unistd.h>

int main() {
  int r;

  r = fork();
  if (r < 0) {
     // Error
  } else if (r > 0) {
    // Parent
  } else /* r == 0 */ {
    // Child
  }
}
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{Utilisation de threads}
\begin{lstlisting}
#include <pthread.h>

void *task(void *arg) {
  int val = (int) arg;
  // Child
}

int main() {
  int arg = 42
  pthread_t id;
  pthread_create(&id, NULL, task, (void *) arg);
  // Parent
}
\end{lstlisting}
\end{frame}


\note{Montrer l'arborescence du kernel: mm, kernel, include, arch, drivers, scripts, tools, Documentation, }
